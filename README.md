# Overview 

The goal of this repo is create an auto-label generation pipeline. The are two stages in how labels are generated: 

1. Dataset Preprocessing - stage_one.py
2. Label Generation - stage_two.py

## 1. Dataset Preprocessing 

This step cleans your data and processes it such that labels can be generated. The steps taken in this stage are outlined below. 

1. Clean Dataset:
    * Remove urls
    * Remove emojis
    * Remove whitespace
    * Remove any text below length 3
    * Remove any text containing: [removed][deleted] - this is specific to reddit dataset
    * Remove any text containing a language not accepted by Llama3
        * languages accepted by LLama: English, French, German, Italian, Portuguese, Dutch, Russian, Chinese, Japanese and Korean
2. Create Text Embeddings 
    * Using a multilingual sentence transformer embeddings are created
3. Dimension Reduction
    * Use UMAP to reduce the dimensions of the previously generated text embeddings  
5. Cluster
    * This module uses an optimized hyperparameter search that prioritizes topic diversity and reducing the number of clusters
    * Module uses HDBSCAN for creating clusters
6. Save the data to a csv file given a specified path
     * Default behaviour saves the cleaned text, dimensions and cluster label to a csv file
         * default path is output.csv  

## 2. Label Generation 

This is the step that generates labels

1. Create representational text for each cluster
    * This works currently by sampling the text with the most number of tokens and creating a string till the threshold for the max number of tokens has reached
2. Create Labels
    * Generate Labels General: Depending on the parameters passed to this module two things can happen:
        * Takes two parameters:
            * sys_id: index of the system prompt to be used from prompt.py
            * user_id: index of the user prompt to be used from prompt.py
            * cove_id: index of the chain of verification questions to be used from prompt.py              
        *  Generate Labels (Chain-of-Thought)
            * Only execute Chain-of-Thought prompt if no cove_id given
        * Generate Labels (Chain-of-Verification) 
            * Only execute Chain-of-Verification prompt if cove_id given
3. Save output to a specified file
    * Save the dimensions, text, cluster label and the label generated by the LLM
  
# Running the scripts

## Data Preprocessing 

Run the command:   

```
bash create_inter.sh file_path 
```

* file_path: name of the file excluding the .csv suffix, the shell script assumes that the directory results/benchmark/file_path exists
* a .csv file will be created with the name of results/benchmark/file_path/file_path_inter.csv 

## Label Generation 

Run the command: 

```
bash create_cove_label_one.sh file_path dir user_prompt_id 
```

* file_path: the name of the clustered file
* dir: directory to be saved in (must be already created)
* user_prompt_id: index of wanted user prompt
* a .csv file will be created in the results/benchmark/dir/file_path_cove_label_one.csv 

Run the command: 

```
bash create_cove_label_two.sh file_path dir user_prompt_id 
```

* file_path: the name of the clustered file
* dir: directory to be saved in (must be already created)
* user_prompt_id: index of wanted user prompt
* a .csv file will be created in the results/benchmark/dir/file_path_cove_label_two.csv 



